{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02eaf58c",
   "metadata": {},
   "source": [
    "# Aerial 6G Call Studio (Colab Demo)\n",
    "\n",
    "This notebook is a fully functional, Colab-friendly companion to the `web_demo` call planner.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NVIDIA/aerial-cuda-accelerated-ran/blob/main/web_demo/Aerial_6G_Call_Studio_Demo.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f60af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88383f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_URL = \"https://raw.githubusercontent.com/NVIDIA/aerial-cuda-accelerated-ran/main/web_demo/data/demo-data.json\"\n",
    "LOCAL_DATA = Path(\"web_demo/data/demo-data.json\")\n",
    "\n",
    "if LOCAL_DATA.exists():\n",
    "    demo_data = json.loads(LOCAL_DATA.read_text(encoding=\"utf-8\"))\n",
    "    source = f\"local file: {LOCAL_DATA}\"\n",
    "else:\n",
    "    with urlopen(RAW_DATA_URL) as response:\n",
    "        demo_data = json.load(response)\n",
    "    source = f\"remote URL: {RAW_DATA_URL}\"\n",
    "\n",
    "print(f\"Loaded demo data from {source}\")\n",
    "print(\"Profiles:\", \", \".join(p[\"name\"] for p in demo_data[\"perf_profiles\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed02f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAFFIC_TUNING = {\n",
    "    \"voice\": {\"latency_bias\": -0.8, \"prb_scale\": 0.7, \"reliability_boost\": 0.003, \"slice\": \"URLLC\"},\n",
    "    \"video\": {\"latency_bias\": 1.9, \"prb_scale\": 1.5, \"reliability_boost\": -0.004, \"slice\": \"eMBB\"},\n",
    "    \"iot\": {\"latency_bias\": 0.2, \"prb_scale\": 0.45, \"reliability_boost\": 0.006, \"slice\": \"mMTC\"},\n",
    "}\n",
    "\n",
    "PROFILE_MAP = {p[\"name\"]: p for p in demo_data[\"perf_profiles\"]}\n",
    "\n",
    "\n",
    "def clamp(value, low, high):\n",
    "    return min(max(value, low), high)\n",
    "\n",
    "\n",
    "def generate_sessions(profile_name, traffic_type, concurrency):\n",
    "    profile = PROFILE_MAP[profile_name]\n",
    "    tuning = TRAFFIC_TUNING[traffic_type]\n",
    "    density = profile[\"num_testcases\"] / max(profile[\"groups\"], 1)\n",
    "    base_latency = 2.4 + profile[\"groups\"] * 0.4 + tuning[\"latency_bias\"]\n",
    "    base_prb = round((14 + density) * tuning[\"prb_scale\"])\n",
    "    reliability = clamp(0.992 + tuning[\"reliability_boost\"] - profile[\"groups\"] * 0.0007, 0.97, 0.99999)\n",
    "\n",
    "    sessions = []\n",
    "    for idx in range(8):\n",
    "        jitter = ((idx % 3) - 1) * 0.28\n",
    "        sessions.append(\n",
    "            {\n",
    "                \"session_id\": f\"{profile_name.upper()}-{idx + 1:03d}\",\n",
    "                \"slice\": tuning[\"slice\"],\n",
    "                \"prbs\": max(8, round(base_prb + idx * 2)),\n",
    "                \"latency_ms\": clamp(base_latency + jitter + concurrency / 140, 1.2, 20),\n",
    "                \"reliability\": clamp(reliability - idx * 0.0003, 0.95, 0.99999),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    throughput_gbps = concurrency * base_prb * (0.0016 if traffic_type == \"video\" else 0.0007)\n",
    "    gpu_load = clamp((concurrency / 2.2) + profile[\"groups\"] * 2.3, 8, 100)\n",
    "    avg_latency = sum(s[\"latency_ms\"] for s in sessions) / len(sessions)\n",
    "\n",
    "    metrics = {\n",
    "        \"throughput_gbps\": throughput_gbps,\n",
    "        \"avg_latency_ms\": avg_latency,\n",
    "        \"target_reliability\": reliability,\n",
    "        \"gpu_load_index\": gpu_load,\n",
    "    }\n",
    "    return sessions, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aea037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_call_plan(profile_name, traffic_type, concurrency):\n",
    "    sessions, metrics = generate_sessions(profile_name, traffic_type, concurrency)\n",
    "    df = pd.DataFrame(sessions)\n",
    "\n",
    "    metric_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Metric\": [\"Estimated Throughput\", \"Avg Latency\", \"Target Reliability\", \"GPU Load Index\"],\n",
    "            \"Value\": [\n",
    "                f\"{metrics['throughput_gbps']:.2f} Gbps\",\n",
    "                f\"{metrics['avg_latency_ms']:.2f} ms\",\n",
    "                f\"{metrics['target_reliability'] * 100:.3f}%\",\n",
    "                f\"{metrics['gpu_load_index']:.1f} / 100\",\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    display(metric_df)\n",
    "    display(df.style.format({\"latency_ms\": \"{:.2f}\", \"reliability\": \"{:.5f}\"}))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    ax[0].bar(df[\"session_id\"], df[\"latency_ms\"], color=\"#4F81BD\")\n",
    "    ax[0].set_title(\"Session Latency\")\n",
    "    ax[0].set_ylabel(\"ms\")\n",
    "    ax[0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    ax[1].plot(df[\"session_id\"], df[\"prbs\"], marker=\"o\", color=\"#9BBB59\")\n",
    "    ax[1].set_title(\"PRB Allocation\")\n",
    "    ax[1].set_ylabel(\"PRBs\")\n",
    "    ax[1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "profile_widget = widgets.Dropdown(options=sorted(PROFILE_MAP.keys()), description=\"Profile\")\n",
    "traffic_widget = widgets.Dropdown(options=[\"voice\", \"video\", \"iot\"], value=\"video\", description=\"Traffic\")\n",
    "concurrency_widget = widgets.IntSlider(value=80, min=10, max=200, step=5, description=\"Concurrency\")\n",
    "\n",
    "ui = widgets.VBox([profile_widget, traffic_widget, concurrency_widget])\n",
    "out = widgets.interactive_output(\n",
    "    render_call_plan,\n",
    "    {\n",
    "        \"profile_name\": profile_widget,\n",
    "        \"traffic_type\": traffic_widget,\n",
    "        \"concurrency\": concurrency_widget,\n",
    "    },\n",
    ")\n",
    "\n",
    "display(ui, out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17004c4e",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- This notebook reproduces the same synthetic KPI/session logic used in `web_demo/main.js`.\n",
    "- Use it for quick demos, experimentation, or as a baseline before connecting real runtime telemetry.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}